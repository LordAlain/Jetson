{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest training checkpoint is  ./255_reg_model/checkpoint-42840\n",
      "INFO:tensorflow:Restoring parameters from ./255_reg_model/checkpoint-42840\n",
      "Epoch 1 -- Train acc.: 0.9259, Validation acc.: 0.9230, Test acc.: 0.8553, Elapsed time: 17.91 sec\n",
      "Epoch 2 -- Train acc.: 0.9213, Validation acc.: 0.9176, Test acc.: 0.8502, Elapsed time: 15.92 sec\n",
      "Epoch 3 -- Train acc.: 0.9199, Validation acc.: 0.9174, Test acc.: 0.8476, Elapsed time: 15.84 sec\n",
      "Epoch 4 -- Train acc.: 0.9177, Validation acc.: 0.9162, Test acc.: 0.8471, Elapsed time: 15.89 sec\n",
      "Epoch 5 -- Train acc.: 0.9169, Validation acc.: 0.9154, Test acc.: 0.8445, Elapsed time: 15.74 sec\n",
      "Epoch 6 -- Train acc.: 0.9153, Validation acc.: 0.9138, Test acc.: 0.8414, Elapsed time: 15.73 sec\n",
      "Epoch 7 -- Train acc.: 0.9148, Validation acc.: 0.9130, Test acc.: 0.8411, Elapsed time: 15.87 sec\n",
      "Epoch 8 -- Train acc.: 0.9144, Validation acc.: 0.9140, Test acc.: 0.8405, Elapsed time: 15.87 sec\n",
      "Epoch 9 -- Train acc.: 0.9138, Validation acc.: 0.9127, Test acc.: 0.8413, Elapsed time: 15.83 sec\n",
      "Epoch 10 -- Train acc.: 0.9134, Validation acc.: 0.9130, Test acc.: 0.8394, Elapsed time: 16.08 sec\n",
      "Model Saved !!! 9 \n",
      "\n",
      "Epoch 11 -- Train acc.: 0.9134, Validation acc.: 0.9128, Test acc.: 0.8409, Elapsed time: 17.69 sec\n",
      "Epoch 12 -- Train acc.: 0.9142, Validation acc.: 0.9118, Test acc.: 0.8403, Elapsed time: 15.84 sec\n",
      "Epoch 13 -- Train acc.: 0.9120, Validation acc.: 0.9110, Test acc.: 0.8394, Elapsed time: 15.89 sec\n",
      "Epoch 14 -- Train acc.: 0.9146, Validation acc.: 0.9128, Test acc.: 0.8396, Elapsed time: 15.82 sec\n",
      "Epoch 15 -- Train acc.: 0.9151, Validation acc.: 0.9133, Test acc.: 0.8386, Elapsed time: 15.92 sec\n",
      "Epoch 16 -- Train acc.: 0.9149, Validation acc.: 0.9141, Test acc.: 0.8401, Elapsed time: 15.91 sec\n",
      "Epoch 17 -- Train acc.: 0.9155, Validation acc.: 0.9149, Test acc.: 0.8433, Elapsed time: 15.85 sec\n",
      "Epoch 18 -- Train acc.: 0.9145, Validation acc.: 0.9123, Test acc.: 0.8404, Elapsed time: 15.87 sec\n",
      "Epoch 19 -- Train acc.: 0.9134, Validation acc.: 0.9116, Test acc.: 0.8405, Elapsed time: 15.94 sec\n",
      "Epoch 20 -- Train acc.: 0.9136, Validation acc.: 0.9118, Test acc.: 0.8408, Elapsed time: 15.88 sec\n",
      "Model Saved !!! 19 \n",
      "\n",
      "Epoch 21 -- Train acc.: 0.9145, Validation acc.: 0.9121, Test acc.: 0.8407, Elapsed time: 17.24 sec\n",
      "Epoch 22 -- Train acc.: 0.9154, Validation acc.: 0.9128, Test acc.: 0.8420, Elapsed time: 15.93 sec\n",
      "Epoch 23 -- Train acc.: 0.9145, Validation acc.: 0.9126, Test acc.: 0.8397, Elapsed time: 15.91 sec\n",
      "Epoch 24 -- Train acc.: 0.9157, Validation acc.: 0.9125, Test acc.: 0.8428, Elapsed time: 15.86 sec\n",
      "Epoch 25 -- Train acc.: 0.9154, Validation acc.: 0.9123, Test acc.: 0.8412, Elapsed time: 15.98 sec\n",
      "Epoch 26 -- Train acc.: 0.9158, Validation acc.: 0.9130, Test acc.: 0.8442, Elapsed time: 15.91 sec\n",
      "Epoch 27 -- Train acc.: 0.9148, Validation acc.: 0.9123, Test acc.: 0.8427, Elapsed time: 15.88 sec\n",
      "Epoch 28 -- Train acc.: 0.9153, Validation acc.: 0.9123, Test acc.: 0.8430, Elapsed time: 15.88 sec\n",
      "Epoch 29 -- Train acc.: 0.9158, Validation acc.: 0.9127, Test acc.: 0.8453, Elapsed time: 15.92 sec\n",
      "Epoch 30 -- Train acc.: 0.9151, Validation acc.: 0.9118, Test acc.: 0.8448, Elapsed time: 15.88 sec\n",
      "Model Saved !!! 29 \n",
      "\n",
      "Epoch 31 -- Train acc.: 0.9162, Validation acc.: 0.9137, Test acc.: 0.8459, Elapsed time: 17.30 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ce0fc419c16b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;31m# Perform gradient update (i.e. training step) on current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mKEEP_PROB\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;31m# Calculate training and validation accuracy across the *entire* train/validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;31m# If train/validation size % batch size != 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "from utils import next_batch, calculate_accuracy\n",
    "from model import Model\n",
    "\n",
    "def preprocess_data(X, y):\n",
    "    # Make all image array values fall within the range -1 to 1\n",
    "    # Note all values in original images are between 0 and 255, as uint8\n",
    "    X = X.astype('float32')\n",
    "#     X = (X - 128.) #/ 128.\n",
    "\n",
    "    # Convert the labels from numerical labels to one-hot encoded labels\n",
    "    y_onehot = np.zeros((y.shape[0], NUM_CLASSES))\n",
    "    for i, onehot_label in enumerate(y_onehot):\n",
    "        onehot_label[y[i]] = 1.\n",
    "    y = y_onehot\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Settings/parameters to be used later\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 32  # square image of size IMG_SIZE x IMG_SIZE\n",
    "GRAYSCALE = False  # convert image to grayscale?\n",
    "NUM_CHANNELS = 1 if GRAYSCALE else 3\n",
    "NUM_CLASSES = 43\n",
    "\n",
    "# Model parameters\n",
    "LR = 1e-3  # learning rate\n",
    "KEEP_PROB = 0.5  # dropout keep probability\n",
    "# OPT = tf.train.GradientDescentOptimizer(learning_rate=LR)  # choose which optimizer to use\n",
    "OPT = tf.optimizers.SGD(learning_rate=LR, momentum = 0, nesterov = False, name='SGD')\n",
    "\n",
    "# Training process\n",
    "RESTORE = False  # restore previous model, don't train?\n",
    "RESUME = False  # resume training from previously trained model?\n",
    "\n",
    "NUM_EPOCH = 100\n",
    "coef = 10\n",
    "\n",
    "BATCH_SIZE = 128  # batch size for training (relatively small)\n",
    "BATCH_SIZE_INF = 2048  # batch size for running inference, e.g. calculating accuracy\n",
    "VALIDATION_SIZE = 0.2  # fraction of total training set to use as validation set\n",
    "SAVE_MODEL = True  # save trained model to disk?\n",
    "MODEL_SAVE_PATH = './model.ckpt'  # where to save trained model\n",
    "\n",
    "# Load pickled data\n",
    "\n",
    "with open('train_aug.p', mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_train, y_train = preprocess_data(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "with open('test.p', mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "X_test, y_test = preprocess_data(X_test, y_test)\n",
    "\n",
    "\n",
    "#Train/validation split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=VALIDATION_SIZE)\n",
    "\n",
    "model = Model()\n",
    "\n",
    "x, y, logits, predictions, accuracy = model.x, model.y, model.logits, model.predictions, model.accuracy\n",
    "keep_prob = model.keep_prob\n",
    "loss = model.loss\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "grad_loss = coef * tf.reduce_sum(tf.nn.l2_loss(model.cw_grad))\n",
    "\n",
    "total_loss = model.loss + grad_loss\n",
    "\n",
    "# OPT = tf.train.GradientDescentOptimizer(learning_rate=LR) \n",
    "OPT = tf.optimizers.SGD(learning_rate=LR, momentum = 0, nesterov = False, name='SGD')\n",
    "\n",
    "optimizer = OPT.minimize(total_loss, global_step=global_step)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "if True:\n",
    "\n",
    "\tsaver = tf.train.Saver()\n",
    "\tfilename = tf.train.latest_checkpoint(\"./255_reg_model/\")\n",
    "\tprint(\"Latest training checkpoint is \", filename)\n",
    "\tif filename != None:\n",
    "\t\tsaver.restore(sess, filename)\n",
    "\telse:\n",
    "\t\tsess.run(tf.global_variables_initializer())\n",
    "\n",
    "\tlast_time = time.time()\n",
    "\ttrain_start_time = time.time()\n",
    "\taccuracy_history = []\n",
    "\n",
    "\tfor epoch in range(NUM_EPOCH):\n",
    "\t\t# Instantiate generator for training data\n",
    "\t\ttrain_gen = next_batch(X_train, y_train, BATCH_SIZE, True)\n",
    "\n",
    "\t\t# How many batches to run per epoch\n",
    "\t\tnum_batches_train = math.ceil(X_train.shape[0] / BATCH_SIZE)\n",
    "\n",
    "\t\t# Run training on each batch\n",
    "\t\tfor _ in range(num_batches_train):\n",
    "\t\t\t# Obtain the training data and labels from generator\n",
    "\t\t\timages, labels = next(train_gen)\n",
    "\n",
    "\t\t\t# Perform gradient update (i.e. training step) on current batch\n",
    "\t\t\tsess.run(optimizer, feed_dict={x: images, y: labels, keep_prob: KEEP_PROB})\n",
    "\t\t# Calculate training and validation accuracy across the *entire* train/validation set\n",
    "\t\t# If train/validation size % batch size != 0\n",
    "\t\t# then we must calculate weighted average of the accuracy of the final (partial) batch,\n",
    "\t\t# w.r.t. the rest of the full batches\n",
    "\n",
    "\t\t# Training set\n",
    "\t\ttrain_gen = next_batch(X_train, y_train, BATCH_SIZE_INF, True)\n",
    "\t\ttrain_size = X_train.shape[0]\n",
    "\t\ttrain_acc = calculate_accuracy(train_gen, train_size, BATCH_SIZE_INF, accuracy, x, y, keep_prob, sess)\n",
    "\n",
    "\t\t# Validation set\n",
    "\t\tvalid_gen = next_batch(X_valid, y_valid, BATCH_SIZE_INF, True)\n",
    "\t\tvalid_size = X_valid.shape[0]\n",
    "\t\tvalid_acc = calculate_accuracy(valid_gen, valid_size, BATCH_SIZE_INF, accuracy, x, y, keep_prob, sess)\n",
    "        \n",
    "\n",
    "\t\ttest_gen = next_batch(X_test, y_test, BATCH_SIZE_INF, False)\n",
    "\t\ttest_size = X_test.shape[0]\n",
    "\t\ttest_acc = calculate_accuracy(test_gen, test_size, BATCH_SIZE_INF, accuracy, x, y, keep_prob, sess)\n",
    "\n",
    "\n",
    "\t\t# Record and report train/validation/test accuracies for this epoch\n",
    "\t\taccuracy_history.append((train_acc, valid_acc))\n",
    "\n",
    "\t\tprint('Epoch %d -- Train acc.: %.4f, Validation acc.: %.4f, Test acc.: %.4f, Elapsed time: %.2f sec' %\\\n",
    "\t\t    (epoch+1, train_acc, valid_acc, test_acc, time.time() - last_time))\n",
    "\t\tlast_time = time.time()\n",
    "\n",
    "\t\tif epoch % 10 == 9:\n",
    "\t\t#     # Also save accuracy history\n",
    "\t\t#     print('Accuracy history saved at accuracy_history.p')\n",
    "\t\t#     with open('accuracy_history.p', 'wb') as f:\n",
    "\t\t#         pickle.dump(accuracy_history, f)\n",
    "\t\t    saver.save(sess, os.path.join(\"./255_reg_model\", 'checkpoint'), global_step=global_step)\n",
    "\t\t    print('Model Saved !!!', epoch, \"\\n\")\n",
    "\n",
    "\ttotal_time = time.time() - train_start_time\n",
    "\tprint('Total elapsed time: %.2f sec (%.2f min)' % (total_time, total_time/60))\n",
    "\n",
    "\t# After training is complete, evaluate accuracy on test set\n",
    "\tprint('Calculating test accuracy...')\n",
    "\ttest_gen = next_batch(X_test, y_test, BATCH_SIZE_INF, False)\n",
    "\ttest_size = X_test.shape[0]\n",
    "\ttest_acc = calculate_accuracy(test_gen, test_size, BATCH_SIZE_INF, accuracy, x, y, keep_prob, sess)\n",
    "\tprint('Test acc.: %.4f' % (test_acc,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008878255\n"
     ]
    }
   ],
   "source": [
    "train_gen = next_batch(X_train, y_train, BATCH_SIZE, True)\n",
    "images, labels = next(train_gen)\n",
    "gloss = sess.run(model.grad_loss, feed_dict={x: images, y: labels, keep_prob: KEEP_PROB})\n",
    "\n",
    "print(gloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest training checkpoint is  ./natural_model/checkpoint-10080\n",
      "INFO:tensorflow:Restoring parameters from ./natural_model/checkpoint-10080\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "filename = tf.train.latest_checkpoint(\"./natural_model/\")\n",
    "print(\"Latest training checkpoint is \", filename)\n",
    "if filename != None:\n",
    "    saver.restore(sess, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04386959\n"
     ]
    }
   ],
   "source": [
    "train_gen = next_batch(X_train, y_train, BATCH_SIZE, True)\n",
    "images, labels = next(train_gen)\n",
    "gloss = sess.run(model.grad_loss, feed_dict={x: images, y: labels, keep_prob: KEEP_PROB})\n",
    "\n",
    "print(gloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
