{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9afb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from imageio import imread\n",
    "# from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import pprint\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b00af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import (Flatten, Dense, Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa55f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os.path\n",
    "if not os.path.exists(\"GTSRB_Final_Training_Images.zip\"):\n",
    "    # Get file from URL\n",
    "    url = \"\"\n",
    "    filename = \"./GTSRB_Final_Training_Images.zip\"\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f9ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "X, Xt, y, yt = list(), list(), list(), list()\n",
    "\n",
    "archive = zipfile.ZipFile('./GTSRB_Final_Training_Images.zip', 'r')\n",
    "\n",
    "file_paths = [file for file in archive.namelist() \n",
    "              if '.ppm' in file]\n",
    "\n",
    "for filename in file_paths:\n",
    "    with archive.open(filename) as img_file:\n",
    "\n",
    "        img = imread(img_file.read())\n",
    "        img = resize(img,\n",
    "                     output_shape=(IMG_SIZE, IMG_SIZE),\n",
    "                     mode='reflect',\n",
    "                     anti_aliasing=True\n",
    "                    )\n",
    "        img_class = int(filename.split('/')[-2])\n",
    "        \n",
    "\n",
    "#     img = imread(archive.open(filename))\n",
    "#     img = resize(img,\n",
    "#                  output_shape=(IMG_SIZE, IMG_SIZE),\n",
    "#                  mode='reflect',\n",
    "#                  anti_aliasing=True\n",
    "#                 )\n",
    "#     img_class = int(filename.split('/')[-2])\n",
    "\n",
    "    if (hash(filename) % 1000) / 1000 > TEST_SIZE:\n",
    "        X.append(img)\n",
    "        y.append(img_class)\n",
    "    else:\n",
    "        Xt.append(img)\n",
    "        yt.append(img_class)\n",
    "archive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d653e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No classes:43\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ratio = len(Xt) / len(file_paths)\n",
    "# print(\"Train size: {} test size: {} ({:0.3f})\").format(\n",
    "#     len(X), \n",
    "#     len(Xt),\n",
    "#     test_ratio)\n",
    "\n",
    "classes, dist = np.unique(y+yt, return_counts = True)\n",
    "NUM_CLASSES = len(classes)\n",
    "print(\"No classes:{}\".format(NUM_CLASSES))\n",
    "\n",
    "plt.bar(classes, dist, align = 'center', alpha = 0.5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################\n",
    "# # Neural network architecture\n",
    "# ########################################################\n",
    "# def neural_network():\n",
    "# \t\"\"\"\n",
    "# \tDefine neural network architecture\n",
    "# \tReturn relevant tensor references\n",
    "# \t\"\"\"\n",
    "# \twith tf.variable_scope('neural_network'):\n",
    "# \t\t# Tensors representing input images and labels\n",
    "# \t\tx = tf.placeholder('float', [None, IMG_SIZE, IMG_SIZE, NUM_CHANNELS])\n",
    "# \t\ty = tf.placeholder('float', [None, NUM_CLASSES])\n",
    "\n",
    "# \t\t# Placeholder for dropout keep probability\n",
    "# \t\tkeep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# \t\t# Neural network architecture: Convolutional Neural Network (CNN)\n",
    "# \t\t# Using TensorFlow-Slim to build the network:\n",
    "# \t\t# https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim\n",
    "\n",
    "# \t\t# Use batch normalization for all convolution layers\n",
    "# \t\twith slim.arg_scope([slim.conv2d], normalizer_fn=slim.batch_norm):\n",
    "# \t\t\t# Given x shape is (32, 32, 3)\n",
    "# \t\t\t# Conv and pool layers\n",
    "# \t\t\tnet = Conv2D(x, 16, [3, 3], scope='conv0')  # output shape: (32, 32, 16)\n",
    "# \t\t\tnet = MaxPool2D(net, [3, 3], 1, padding='SAME', scope='pool0')  # output shape: (32, 32, 16)\n",
    "# \t\t\tnet = Conv2D(net, 64, [5, 5], 3, padding='VALID', scope='conv1')  # output shape: (10, 10, 64)\n",
    "# \t\t\tnet = MaxPool2D(net, [3, 3], 1, scope='pool1')  # output shape: (8, 8, 64)\n",
    "# \t\t\tnet = Conv2D(net, 128, [3, 3], scope='conv2')  # output shape: (8, 8, 128)\n",
    "# \t\t\tnet = Conv2D(net, 64, [3, 3], scope='conv3')  # output shape: (8, 8, 64)\n",
    "# \t\t\tnet = MaxPool2D(net, [3, 3], 1, scope='pool3')  # output shape: (6, 6, 64)\n",
    "\n",
    "# \t\t\t# Final fully-connected layers\n",
    "# \t\t\tnet = Flatten(net)\n",
    "# \t\t\tnet = Dense(net, 1024, scope='fc4')\n",
    "# \t\t\tnet = Dropout(net, keep_prob)\n",
    "\n",
    "# \t\t\tnet = Dense(net, 1024, scope='fc5')\n",
    "# \t\t\tnet = Dropout(net, keep_prob)\n",
    "# \t\t\tnet = Dense(net, NUM_CLASSES, scope='fc6')\n",
    "# \t\t# Final output (logits)\n",
    "# \t\tlogits = net\n",
    "\n",
    "# \t\t# Loss (data loss and regularization loss) and optimizer\n",
    "# \t\tloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y))\n",
    "# \t\toptimizer = OPT.minimize(loss)\n",
    "\n",
    "# \t\t# Prediction (used during inference)\n",
    "# \t\tpredictions = tf.argmax(logits, 1)\n",
    "\n",
    "# \t\t# Accuracy metric calculation\n",
    "# \t\tcorrect_predictions = tf.equal(predictions, tf.argmax(y, 1))\n",
    "# \t\taccuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "# \t# Return relevant tensor references\n",
    "# \treturn x, y, keep_prob, logits, optimizer, predictions, accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Use batch normalization for all convolution layers\n",
    "# with slim.arg_scope([slim.conv2d], normalizer_fn=slim.batch_norm):\n",
    "#     # Given x shape is (32, 32, 3)\n",
    "#     # Conv and pool layers\n",
    "#     net = slim.conv2d(x, 16, [3, 3], scope='conv0')  # output shape: (32, 32, 16)\n",
    "#     net = slim.max_pool2d(net, [3, 3], 1, padding='SAME', scope='pool0')  # output shape: (32, 32, 16)\n",
    "#     net = slim.conv2d(net, 64, [5, 5], 3, padding='VALID', scope='conv1')  # output shape: (10, 10, 64)\n",
    "#     net = slim.max_pool2d(net, [3, 3], 1, scope='pool1')  # output shape: (8, 8, 64)\n",
    "#     net = slim.conv2d(net, 128, [3, 3], scope='conv2')  # output shape: (8, 8, 128)\n",
    "#     net = slim.conv2d(net, 64, [3, 3], scope='conv3')  # output shape: (8, 8, 64)\n",
    "#     net = slim.max_pool2d(net, [3, 3], 1, scope='pool3')  # output shape: (6, 6, 64)\n",
    "\n",
    "#     # Final fully-connected layers\n",
    "#     net = tf.contrib.layers.flatten(net)\n",
    "#     net = slim.fully_connected(net, 1024, scope='fc4')\n",
    "#     net = tf.nn.dropout(net, keep_prob)\n",
    "#     net = slim.fully_connected(net, 1024, scope='fc5')\n",
    "#     net = tf.nn.dropout(net, keep_prob)\n",
    "#     net = slim.fully_connected(net, NUM_CLASSES, scope='fc6')\n",
    "# # model.add(Dense(NUM_CLASSES, activation ='softmax'))\n",
    "# return model\n",
    "\n",
    "# model = small_cnn()\n",
    "# model.compile(loss = 'categorical_crossentropu',\n",
    "#              optimizer = Adam(),\n",
    "#              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d27bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit_generator(train_gen,\n",
    "#                              steps_per_epoch = len(X), // batch_size\n",
    "#                              validation_data = val_gen,\n",
    "#                              validation_steps = len(Xt), // batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
